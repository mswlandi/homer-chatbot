{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"homer_chatbot.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"n4JyBRBILBDX","colab_type":"text"},"source":["# Chatbot que é o Homer Simpson usando tf Seq2Seq\n","![alt text](https://drive.google.com/uc?id=1oU6A7qPq7gn4T342pxqQep0i1RszRSka)"]},{"cell_type":"markdown","metadata":{"id":"jT7lAVW_8CZX","colab_type":"text"},"source":["## 1. Motivação\n","Quando ouvimos que o enunciado do projeto final era criar \"qualquer\" chatbot, utilizando \"qualquer\" tecnologia, logo tivemos a brilhante ideia de criar um modelo de redes neurais que aprende a conversar, claro, se conseguíssemos um conjunto de dados grande o bastante...\n","\n","\n","Um de nós então se lembrou do conjunto de dados de falas dos episódios de Os Simpsons desde 1989 até 2015 - e assim começou a nossa jornada para criar uma IA cujo único propósito de existência é ser o Homer Simpson.\n","\n","![fig 1.1: expectativa](https://drive.google.com/uc?id=1QK2evq6RIFyav6zEHhTKXto1zBLZz_T2)"]},{"cell_type":"markdown","metadata":{"id":"3VQ6-rBHbJvv","colab_type":"text"},"source":["## 2. Introdução\n","Nós resolvemos fazer o ChatBot utilizando o modelo de redes neurais _Seq2Seq_, e mais tarde, após resultados não muito promissores ~~(spoiler)~~, utilizando o modelo _Doc2Vec_. Para entender por que nenhum dos dois modelos deu muito certo ~~(spoiler 2)~~, vamos primeiro dar uma olhada no conjunto de dados, e mais tarde nos dois modelos. \n","\n","Depois, fazemos experimentações com outras pessoas, e por fim, concluimos fazendo uma ligação do que foi feito aqui com o que foi visto na cadeira de Linguagens Formais e Autômatos.\n","\n","Porém, antes que possamos prosseguir, caso o leitor deseje rodar os códigos, é preciso que copie a [pasta do drive do projeto](https://drive.google.com/open?id=1cs3x5OpAML9lGeDbHjby7GSifKu0X5P_), e o cole dentro da pasta principal do seu Google Drive (My Drive), pois todas as células de código tomam este diretório e seus arquivos como referência."]},{"cell_type":"markdown","metadata":{"id":"JFH82YqcbMuW","colab_type":"text"},"source":["### 2.1. Conjunto de Dados\n","O conjunto pode ser encontrado [aqui](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data#simpsons_script_lines.csv), e contém falas de mais ou menos 600 episódios, totalizando mais de 100 mil falas.\n","\n","![alt text](https://drive.google.com/uc?id=1VcaPZlBaODBt1qB7IH-dQ8vpTaLlHJQz)\n","\n","Como pode-se ver, cada linha corresponde a uma fala, e possui 13 colunas (algumas escondidas na imagem), com diversas informações que podem ser potencialmente úteis, como o local, quem fala, e claro, a própria fala.\n","\n","Você pode estar pensando \"~~$@#&@#~~ 100k falas é muita fala!\", mas eu vou explicar porque não é o caso:\n","- No [tutorial de tradução neural do TensorFlow](https://github.com/tensorflow/nmt), o conjunto de dados chamado de \"Small Scale\" possui 133k pares de falas\n","- No caso do modelo _Seq2Seq_, é preciso separar uma parte do conjunto de dados para ser o conjunto de validação (mais sobre isso a seguir), e não é usado para treinar a IA.\n","- Nem todas as falas são falas utilizáveis para nossos propósitos:\n","  - Algumas nem são de diálogo\n","  - Como a IA vai imitar o Homer, só podemos usar as falas dele, e as falas de outros personagens para ele. (no caso do modelo Doc2Vec podemos usar todas falas para treinar, mais sobre isso adiante)\n","  - Como os dois modelos recebem frases como entrada, devemos concatenar falas consequintes (do homer e para o homer) em uma só.\n","\n","Após todos estes filtros, nos resta apenas 15k pares de falas, o que pode ser considerado insuficiente para treinar uma rede neural do zero para simular um personagem como o Homer."]},{"cell_type":"markdown","metadata":{"id":"JTQHuT8ObSpN","colab_type":"text"},"source":["### 2.2. Conjunto de Treino\n","\n","Usando dois scripts em python (estão no repositório), organizamos o conjunto de dados da seguinte forma:\n","\n","- Seq2Seq: (train foram usados no treino, test foram usados na validação)\n","    - **`train.a`** e **`test.a`** - cada linha possui uma fala que foi dita antes de uma fala do Homer (sim, estamos ignorando os casos em que a fala que foi dita antes não tenha sido falada para o Homer)\n","    -  **`train.b`** e **`test.b`** - cada linha possui uma fala que foi dita pelo Homer.\n","- Doc2Vec: (mesma coisa que os do Seq2Seq, mas todas as falas do Homer ficam antes)\n","    - **`questions.txt`** - mesmo caso dos arquivos **`.a`** do Seq2Seq\n","    - **`answers.txt`** - mesmo caso dos arquivos **`.b`** do Seq2Seq\n"]},{"cell_type":"code","metadata":{"id":"COpS1Tf4K0ts","colab_type":"code","colab":{}},"source":["# Fazendo o Drive estar disponível como pastas acessíveis para o python e shell\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dfDoVL895cF","colab_type":"code","colab":{}},"source":["%%bash\n","# Copiando os dados de treino e teste do Drive para a pasta de trabalho - Seq2Seq\n","cp /content/gdrive/My\\ Drive/homer_chatbot/homer_train.a ./train.a\n","cp /content/gdrive/My\\ Drive/homer_chatbot/homer_train.b ./train.b\n","cp /content/gdrive/My\\ Drive/homer_chatbot/homer_test.a ./test.a\n","cp /content/gdrive/My\\ Drive/homer_chatbot/homer_test.b ./test.b"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"71WLdhuiK8gw","colab_type":"code","colab":{}},"source":["%%bash\n","# Copiando os dados de treino e teste do Drive para a pasta de trabalho - Doc2Vec\n","cp /content/gdrive/My\\ Drive/homer_chatbot/questions.txt\\\n","   /content/questions.txt\n","cp /content/gdrive/My\\ Drive/homer_chatbot/answers.txt\\\n","   /content/answers.txt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"png35bzy_rl_","colab_type":"text"},"source":["## 3. Modelo Seq2Seq\n","\n","Tendo os arquivos organizados em seus devidos formatos, vamos falar sobre o primeiro modelo - [Seq2Seq](https://google.github.io/seq2seq/). Seq2Seq é um modelo criado pela Google para \"Tradução Automática, Sumarização de Texto, **Modelagem Conversacional**, Legendas automáticas de Imagens, e mais\". Ele é um modelo generativo, ou seja, gera dados novos a partir do aprendizado que ele teve com os dados de entrada.\n","\n","Na verdade, vamos utilizar um modelo já construido usando Seq2Seq, o TernsorFlow-nmt, feito para tradução neural, mas ao invés de traduzir frases de uma língua para a outra, vamos traduzir frases para o Homer para frases do Homer."]},{"cell_type":"code","metadata":{"id":"sEXk1t75Zjcw","colab_type":"code","outputId":"15daae2a-83d6-414f-c63a-82b58e587d73","executionInfo":{"status":"ok","timestamp":1560014250366,"user_tz":180,"elapsed":3707,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%bash\n","# Baixando o nmt (tf-seq2seq)\n","rm -rf /content/nmt_model\n","rm -rf nmt\n","git clone https://github.com/tensorflow/nmt/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'nmt'...\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"M415Li9_EkU7","colab_type":"text"},"source":["Isso funciona porque tradução neural consiste em abstrair o significado de uma frase em uma língua e traduzir este significado em outra língua, mas o mesmo princípio pode ser usado para chatbots: a rede neural abstrai o significado de uma fala, e a partir dele, busca responder de acordo com este significado, na mesma língua.\n","\n","Na verdade são duas redes neurais em uma - um \"encoder\" - que aprende o significado da frase de entrada, representado por um vetor, e um \"decoder\", que recebe esse vetor, e aprende a responder a ele:\n","\n","![imagens mal feitas são mais legais](https://drive.google.com/uc?id=1oF9AxZ-DpweMJ0vO_5gyaYwqKCSG-szN)\n","\n","Nós dividimos o conjunto de entrada entre _treino_ e _validação_ para evitar o chamado \"over-fitting\" - quando o modelo \"aprende demais\". A seguir uma imagem que explica intuitivamente como um modelo de predição pode aprender demais:\n","\n","![sim, fiz isso no paint](https://drive.google.com/uc?id=1mrF7OQNLWSALasnYL6As77i1XjFjqUNC)\n","\n","Antes de treinar a rede neural, precisamos montar um _vocabulário_, um conjunto de todas as palavras que a rede neural pode utilizar para entender e responder. Podemos fazer isso apenas dando o conjunto de todas as palavras vistas no conjunto de dados, mas fazer isso criaria um vocabulário potencialmente muito grande, e sem certas conexões úteis entre palavras similares.\n","\n","Uma maneira de resolver isto é dividindo as palavras em sub-palavras, por exemplo \"loved\" seria uma composição de \"lov\" e \"ed\", e \"loving\" seria uma composição de \"lov\" e \"ing\". Isso faz com que o modelo possa generalizar melhor para palavras novas e ainda diminui o tamanho do vocabulário.\n","\n","Existem vários métodos de fazer isso, e o que vamos usar é o Byte-Pair-Encoding (BPE). Para isso, usamos o repositório subword-nmt:"]},{"cell_type":"code","metadata":{"id":"QBLxKYRXF_vA","colab_type":"code","colab":{}},"source":["%%bash\n","# Clonando o repositório subword-nmt\n","rm -rf subword-nmt\n","git clone https://github.com/b0noI/subword-nmt.git\n","cd subword-nmt\n","git checkout dbe97c8f95f14d06b2e46b8053e2e2f9b9bf804e\n","\n","cd /content/\n","\n","# Criando o vocabulário de palavras únicas a partir dos dados de treino\n","subword-nmt/learn_joint_bpe_and_vocab.py --input ./train.a ./train.b -s 50000 -o code.bpe --write-vocabulary vocab.train.bpe.a vocab.train.bpe.b\n","\n","# Removendo os tabs inúteis dos vocabulários\n","sed -i '/\\t/d' ./vocab.train.bpe.a\n","sed -i '/\\t/d' ./vocab.train.bpe.b\n","\n","# Fazendo novos arquivos de vocabulário (sem as frequências, pra usar no tf-seq2seq)\n","cat vocab.train.bpe.a | cut -f1 --delimiter=' ' > revocab.train.bpe.a\n","cat vocab.train.bpe.b | cut -f1 --delimiter=' ' > revocab.train.bpe.b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1L_AA9_6D7vB","colab_type":"text"},"source":["Tendo criado os vocabulários (um para os `.a` e outro para os `.b`), aplicamos ele nos conjuntos de treino."]},{"cell_type":"code","metadata":{"id":"gmdC47TRN5U9","colab_type":"code","colab":{}},"source":["%%bash\n","# Aplicando os vocabulários com sub-palavras em todos os arquivos (treino e teste)\n","subword-nmt/apply_bpe.py -c code.bpe --vocabulary vocab.train.bpe.a --vocabulary-threshold 5 < ./train.a > train.bpe.a\n","subword-nmt/apply_bpe.py -c code.bpe --vocabulary vocab.train.bpe.b --vocabulary-threshold 5 < ./train.b > train.bpe.b\n","subword-nmt/apply_bpe.py -c code.bpe --vocabulary vocab.train.bpe.a --vocabulary-threshold 5 < ./test.a > test.bpe.a\n","subword-nmt/apply_bpe.py -c code.bpe --vocabulary vocab.train.bpe.b --vocabulary-threshold 5 < ./test.b > test.bpe.b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzHlWq1GFRi3","colab_type":"text"},"source":["Esta próxima célula de código só deve ser rodada se quiser carregar do Drive um modelo já\n","treinado anteriormente, para continuar o treinamento ou testar o modelo já treinado"]},{"cell_type":"code","metadata":{"id":"i-QsrsXFrciM","colab_type":"code","colab":{}},"source":["# Carregando modelo treinado anteriormente\n","!rm -rf /content/nmt/nmt_model\n","!cp -r /content/gdrive/My\\ Drive/homer_chatbot/nmt_model /content/nmt/nmt_model\n","!echo -e \"\\nloaded\\n\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8344s4oqGG7-","colab_type":"text"},"source":["E agora, finalmente, o treinamento!"]},{"cell_type":"code","metadata":{"id":"ER64_oNGRZuB","colab_type":"code","outputId":"73036f51-1cbc-4e03-b03d-7d83c3b36a1b","executionInfo":{"status":"ok","timestamp":1558489387679,"user_tz":180,"elapsed":11659,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":14822}},"source":["# Treinando o modelo seq2seq\n","import json\n","\n","# Loop para treinar por 10.000 passos de cada vez,\n","# salvando no drive entre iterações.\n","for i in range(1,50):\n","  \n","  # Atualizando Parâmetro de Passos\n","  filename = '/content/nmt/nmt_model/hparams'\n","  \n","  with open(filename, 'r') as f:\n","    data = json.load(f)\n","    data[\"num_train_steps\"] = i*20*500 + 457690\n","\n","  get_ipython().system(\"rm \" + filename)\n","  with open(filename, 'w') as f:\n","    json.dump(data, f, indent=4)\n","    \n","  # Treinando de fato\n","  !cd nmt && python3 -m nmt.nmt \\\n","    --src=a --tgt=b \\\n","    --vocab_prefix=../revocab.train.bpe \\\n","    --train_prefix=../train.bpe \\\n","    --dev_prefix=../test.bpe \\\n","    --test_prefix=../test.bpe \\\n","    --out_dir=nmt_model \\\n","    --num_layers=2 \\\n","    --num_gpus=1\n","  \n","  # Salvando o progesso\n","  !rm -rf /content/gdrive/My\\ Drive/homer_chatbot/nmt_model\n","  !cp -r /content/nmt/nmt_model /content/gdrive/My\\ Drive/homer_chatbot\n","  !echo -e \"\\nsaved\\n\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","loaded\n","\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","# Job id 0\n","2019-06-01 17:49:46.028738: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-06-01 17:49:46.028932: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3444680 executing computations on platform Host. Devices:\n","2019-06-01 17:49:46.028961: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-06-01 17:49:46.187937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-01 17:49:46.188455: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3443fa0 executing computations on platform CUDA. Devices:\n","2019-06-01 17:49:46.188484: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-06-01 17:49:46.188800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.73GiB freeMemory: 14.60GiB\n","2019-06-01 17:49:46.188823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:49:46.634104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:49:46.634182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:49:46.634194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:49:46.634519: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-06-01 17:49:46.634568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 4887183453169356595), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 8468982386021777706), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 10202005551726348778), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 14800692839, 9346549113963622382)]\n","# Loading hparams from nmt_model/hparams\n","# Vocab file ../revocab.train.bpe.a exists\n","The first 3 vocab words [@@, .@@, the] are not [<unk>, <s>, </s>]\n","# Vocab file ../revocab.train.bpe.b exists\n","The first 3 vocab words [@@, .@@, i] are not [<unk>, <s>, </s>]\n","  saving hparams to nmt_model/hparams\n","  saving hparams to nmt_model/best_bleu/hparams\n","  attention=\n","  attention_architecture=standard\n","  avg_ckpts=False\n","  batch_size=16\n","  beam_width=0\n","  best_bleu=0.2515733643254677\n","  best_bleu_dir=nmt_model/best_bleu\n","  check_special_token=True\n","  colocate_gradients_with_ops=True\n","  coverage_penalty_weight=0.0\n","  decay_scheme=\n","  dev_prefix=../test.bpe\n","  dropout=0.2\n","  embed_prefix=None\n","  encoder_type=uni\n","  eos=</s>\n","  epoch_step=13\n","  forget_bias=1.0\n","  infer_batch_size=32\n","  infer_mode=greedy\n","  init_op=uniform\n","  init_weight=0.1\n","  language_model=False\n","  learning_rate=0.2\n","  length_penalty_weight=0.0\n","  log_device_placement=False\n","  max_gradient_norm=5.0\n","  max_train=0\n","  metrics=['bleu']\n","  num_buckets=5\n","  num_dec_emb_partitions=0\n","  num_decoder_layers=2\n","  num_decoder_residual_layers=0\n","  num_embeddings_partitions=0\n","  num_enc_emb_partitions=0\n","  num_encoder_layers=2\n","  num_encoder_residual_layers=0\n","  num_gpus=1\n","  num_inter_threads=0\n","  num_intra_threads=0\n","  num_keep_ckpts=5\n","  num_sampled_softmax=0\n","  num_train_steps=417690\n","  num_translations_per_input=1\n","  num_units=128\n","  optimizer=sgd\n","  out_dir=nmt_model\n","  output_attention=True\n","  override_loaded_hparams=False\n","  pass_hidden_state=True\n","  random_seed=None\n","  residual=False\n","  sampling_temperature=0.0\n","  share_vocab=False\n","  sos=<s>\n","  src=a\n","  src_embed_file=\n","  src_max_len=50\n","  src_max_len_infer=None\n","  src_vocab_file=nmt_model/revocab.train.bpe.a\n","  src_vocab_size=15230\n","  steps_per_external_eval=None\n","  steps_per_stats=769\n","  subword_option=\n","  test_prefix=../test.bpe\n","  tgt=b\n","  tgt_embed_file=\n","  tgt_max_len=50\n","  tgt_max_len_infer=None\n","  tgt_vocab_file=nmt_model/revocab.train.bpe.b\n","  tgt_vocab_size=14906\n","  time_major=True\n","  train_prefix=../train.bpe\n","  unit_type=lstm\n","  use_char_encode=False\n","  vocab_prefix=../revocab.train.bpe\n","  warmup_scheme=t2t\n","  warmup_steps=0\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:129: DatasetV1.shard (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `dataset.apply(tf.data.experimental.filter_for_shard(...))`.\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.group_by_window(...)`.\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","# Creating train graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  learning_rate=0.2, warmup_steps=0, warmup_scheme=t2t\n","  decay_scheme=, start_decay_step=417690, decay_steps 0, decay_factor 1\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), /device:GPU:0\n","# Creating eval graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), /device:GPU:0\n","# Creating infer graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), \n","# log_file=nmt_model/log_1559411390\n","2019-06-01 17:49:50.009400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:49:50.009459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:49:50.009476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:49:50.009489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:49:50.009781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-06-01 17:49:50.010471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:49:50.010513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:49:50.010527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:49:50.010538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:49:50.010845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-06-01 17:49:50.011837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:49:50.011878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:49:50.011891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:49:50.011903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:49:50.012158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","  loaded train model parameters from nmt_model/translate.ckpt-457690, time 0.21s\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.08s\n","  # 2836\n","2019-06-01 17:49:50.711385: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","    src: dad, if we're really off the gri@@ d, then we won't get power when the air is st@@ ill@@ .\n","    ref: oh. well i'm not cra@@ w@@ ling back to big el@@ e@@ ct@@ ri@@ cit@@ y! from now on, the simpsons are living inter@@ m@@ it@@ t@@ ent@@ ly.\n","    nmt: the gi@@ v@@ en@@ e sounds like a name.\n","  loaded eval model parameters from nmt_model/translate.ckpt-457690, time 0.09s\n","  eval dev: perplexity 784.00, time 7s, Sat Jun  1 17:49:58 2019.\n","  eval test: perplexity 784.00, time 6s, Sat Jun  1 17:50:05 2019.\n","2019-06-01 17:50:05.097538: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:05.097664: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:05.097756: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.04s\n","# External evaluation, global step 457690\n","  decoding to output nmt_model/output_dev\n","  done, num sentences 3062, num translations per input 1, time 7s, Sat Jun  1 17:50:12 2019.\n","  bleu dev: 0.2\n","  saving hparams to nmt_model/hparams\n","# External evaluation, global step 457690\n","  decoding to output nmt_model/output_test\n","  done, num sentences 3062, num translations per input 1, time 7s, Sat Jun  1 17:50:20 2019.\n","  bleu test: 0.2\n","  saving hparams to nmt_model/hparams\n","# Start step 457690, lr 0.2, Sat Jun  1 17:50:21 2019\n","# Init train iterator, skipping 208 elements\n","2019-06-01 17:50:21.524545: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:21.524691: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:21.524794: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.04s\n","  # 259\n","    src: pos@@ si@@ bl@@ y. but the point is, you wanted me to feel better about myself. and i do.\n","    ref: really?\n","    nmt: mmm... p@@ ati@@ p@@ es@@ s.\n","2019-06-01 17:50:21.595133: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:21.595287: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:21.595399: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","  loaded eval model parameters from nmt_model/translate.ckpt-457690, time 0.04s\n","  eval dev: perplexity 784.00, time 6s, Sat Jun  1 17:50:27 2019.\n","  eval test: perplexity 784.00, time 6s, Sat Jun  1 17:50:34 2019.\n","2019-06-01 17:50:34.141639: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:34.141757: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:34.141839: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.04s\n","# External evaluation, global step 457690\n","  decoding to output nmt_model/output_dev\n","  done, num sentences 3062, num translations per input 1, time 7s, Sat Jun  1 17:50:41 2019.\n","  bleu dev: 0.2\n","  saving hparams to nmt_model/hparams\n","# External evaluation, global step 457690\n","  decoding to output nmt_model/output_test\n","  done, num sentences 3062, num translations per input 1, time 7s, Sat Jun  1 17:50:49 2019.\n","  bleu test: 0.2\n","  saving hparams to nmt_model/hparams\n","# Final, step 457690 lr 0.2 step-time 0.00s wps 0.00K ppl 0.00 gN 0.00 dev ppl 784.00, dev bleu 0.2, test ppl 784.00, test bleu 0.2, Sat Jun  1 17:50:50 2019\n","# Done training!, time 28s, Sat Jun  1 17:50:50 2019.\n","# Start evaluating saved best models.\n","2019-06-01 17:50:50.153771: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:50.153895: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","2019-06-01 17:50:50.153934: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","  loaded infer model parameters from nmt_model/best_bleu/translate.ckpt-407690, time 0.04s\n","  # 340\n","    src: oh, po@@ pp@@ a homer, you are so lear@@ ned.\n","    ref: \"@@ lear@@ ned@@ ,\" son, it's pr@@ on@@ ou@@ n@@ c@@ ed \"@@ lear@@ ne@@ d@@ .\"\n","    nmt: fin@@ all@@ y.\n","2019-06-01 17:50:50.218163: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:50.218294: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:50:50.218379: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","  loaded eval model parameters from nmt_model/best_bleu/translate.ckpt-407690, time 0.04s\n","  eval dev: perplexity 724.67, time 6s, Sat Jun  1 17:50:56 2019.\n","  eval test: perplexity 724.67, time 6s, Sat Jun  1 17:51:02 2019.\n","2019-06-01 17:51:02.777759: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:51:02.777899: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:51:02.777986: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","  loaded infer model parameters from nmt_model/best_bleu/translate.ckpt-407690, time 0.04s\n","# External evaluation, global step 407690\n","  decoding to output nmt_model/output_dev\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/nmt/nmt/nmt.py\", line 707, in <module>\n","    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n","    _sys.exit(main(argv))\n","  File \"/content/nmt/nmt/nmt.py\", line 700, in main\n","    run_main(FLAGS, default_hparams, train_fn, inference_fn)\n","  File \"/content/nmt/nmt/nmt.py\", line 693, in run_main\n","    train_fn(hparams, target_session=target_session)\n","  File \"/content/nmt/nmt/train.py\", line 620, in train\n","    summary_writer, sample_src_data, sample_tgt_data)\n","  File \"/content/nmt/nmt/train.py\", line 341, in run_full_eval\n","    summary_writer, avg_ckpts)\n","  File \"/content/nmt/nmt/train.py\", line 279, in run_internal_and_external_eval\n","    test_infer_iterator_feed_dict=test_infer_iterator_feed_dict)\n","  File \"/content/nmt/nmt/train.py\", line 176, in run_external_eval\n","    avg_ckpts=avg_ckpts)\n","  File \"/content/nmt/nmt/train.py\", line 730, in _external_eval\n","    infer_mode=hparams.infer_mode)\n","  File \"/content/nmt/nmt/utils/nmt_utils.py\", line 60, in decode_and_evaluate\n","    nmt_outputs, _ = model.decode(sess)\n","  File \"/content/nmt/nmt/model.py\", line 692, in decode\n","    output_tuple = self.infer(sess)\n","  File \"/content/nmt/nmt/model.py\", line 680, in infer\n","    return sess.run(output_tuple)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n","    options, feed_dict, fetch_list, target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","\n","saved\n","\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","# Job id 0\n","2019-06-01 17:51:29.598281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-06-01 17:51:29.598499: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x175e680 executing computations on platform Host. Devices:\n","2019-06-01 17:51:29.598534: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-06-01 17:51:29.787866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-01 17:51:29.788473: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x175dfa0 executing computations on platform CUDA. Devices:\n","2019-06-01 17:51:29.788508: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-06-01 17:51:29.788890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.73GiB freeMemory: 14.60GiB\n","2019-06-01 17:51:29.788919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:51:30.320649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:51:30.320712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:51:30.320725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:51:30.321046: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-06-01 17:51:30.321107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 10050519637755603665), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12564228744957431492), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 5801415493108660039), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 14800692839, 364202660190210444)]\n","# Loading hparams from nmt_model/hparams\n","# Vocab file ../revocab.train.bpe.a exists\n","The first 3 vocab words [@@, .@@, the] are not [<unk>, <s>, </s>]\n","# Vocab file ../revocab.train.bpe.b exists\n","The first 3 vocab words [@@, .@@, i] are not [<unk>, <s>, </s>]\n","  saving hparams to nmt_model/hparams\n","  saving hparams to nmt_model/best_bleu/hparams\n","  attention=\n","  attention_architecture=standard\n","  avg_ckpts=False\n","  batch_size=16\n","  beam_width=0\n","  best_bleu=0.2515733643254677\n","  best_bleu_dir=nmt_model/best_bleu\n","  check_special_token=True\n","  colocate_gradients_with_ops=True\n","  coverage_penalty_weight=0.0\n","  decay_scheme=\n","  dev_prefix=../test.bpe\n","  dropout=0.2\n","  embed_prefix=None\n","  encoder_type=uni\n","  eos=</s>\n","  epoch_step=13\n","  forget_bias=1.0\n","  infer_batch_size=32\n","  infer_mode=greedy\n","  init_op=uniform\n","  init_weight=0.1\n","  language_model=False\n","  learning_rate=0.2\n","  length_penalty_weight=0.0\n","  log_device_placement=False\n","  max_gradient_norm=5.0\n","  max_train=0\n","  metrics=['bleu']\n","  num_buckets=5\n","  num_dec_emb_partitions=0\n","  num_decoder_layers=2\n","  num_decoder_residual_layers=0\n","  num_embeddings_partitions=0\n","  num_enc_emb_partitions=0\n","  num_encoder_layers=2\n","  num_encoder_residual_layers=0\n","  num_gpus=1\n","  num_inter_threads=0\n","  num_intra_threads=0\n","  num_keep_ckpts=5\n","  num_sampled_softmax=0\n","  num_train_steps=427690\n","  num_translations_per_input=1\n","  num_units=128\n","  optimizer=sgd\n","  out_dir=nmt_model\n","  output_attention=True\n","  override_loaded_hparams=False\n","  pass_hidden_state=True\n","  random_seed=None\n","  residual=False\n","  sampling_temperature=0.0\n","  share_vocab=False\n","  sos=<s>\n","  src=a\n","  src_embed_file=\n","  src_max_len=50\n","  src_max_len_infer=None\n","  src_vocab_file=nmt_model/revocab.train.bpe.a\n","  src_vocab_size=15230\n","  steps_per_external_eval=None\n","  steps_per_stats=769\n","  subword_option=\n","  test_prefix=../test.bpe\n","  tgt=b\n","  tgt_embed_file=\n","  tgt_max_len=50\n","  tgt_max_len_infer=None\n","  tgt_vocab_file=nmt_model/revocab.train.bpe.b\n","  tgt_vocab_size=14906\n","  time_major=True\n","  train_prefix=../train.bpe\n","  unit_type=lstm\n","  use_char_encode=False\n","  vocab_prefix=../revocab.train.bpe\n","  warmup_scheme=t2t\n","  warmup_steps=0\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:129: DatasetV1.shard (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `dataset.apply(tf.data.experimental.filter_for_shard(...))`.\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.group_by_window(...)`.\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","# Creating train graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  learning_rate=0.2, warmup_steps=0, warmup_scheme=t2t\n","  decay_scheme=, start_decay_step=427690, decay_steps 0, decay_factor 1\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), /device:GPU:0\n","# Creating eval graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), /device:GPU:0\n","# Creating infer graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), \n","# log_file=nmt_model/log_1559411494\n","2019-06-01 17:51:34.082618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:51:34.082679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:51:34.082694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:51:34.082709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:51:34.082996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-06-01 17:51:34.083721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:51:34.083762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:51:34.083775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:51:34.083788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:51:34.084136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-06-01 17:51:34.085357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:51:34.085400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:51:34.085413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:51:34.085427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:51:34.085684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","  loaded train model parameters from nmt_model/translate.ckpt-457690, time 0.18s\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.09s\n","  # 834\n","2019-06-01 17:51:34.733464: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","    src: are you read@@ y?\n","    ref: i just gotta put my sho@@ es on.\n","    nmt: i can't afford a du@@ de@@ !\n","  loaded eval model parameters from nmt_model/translate.ckpt-457690, time 0.09s\n","  eval dev: perplexity 784.00, time 6s, Sat Jun  1 17:51:42 2019.\n","  eval test: perplexity 784.00, time 6s, Sat Jun  1 17:51:49 2019.\n","2019-06-01 17:51:49.050309: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:51:49.050416: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","2019-06-01 17:51:49.050453: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.04s\n","# External evaluation, global step 457690\n","  decoding to output nmt_model/output_dev\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/nmt/nmt/nmt.py\", line 707, in <module>\n","    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n","    _sys.exit(main(argv))\n","  File \"/content/nmt/nmt/nmt.py\", line 700, in main\n","    run_main(FLAGS, default_hparams, train_fn, inference_fn)\n","  File \"/content/nmt/nmt/nmt.py\", line 693, in run_main\n","    train_fn(hparams, target_session=target_session)\n","  File \"/content/nmt/nmt/train.py\", line 508, in train\n","    sample_tgt_data, avg_ckpts)\n","  File \"/content/nmt/nmt/train.py\", line 341, in run_full_eval\n","    summary_writer, avg_ckpts)\n","  File \"/content/nmt/nmt/train.py\", line 279, in run_internal_and_external_eval\n","    test_infer_iterator_feed_dict=test_infer_iterator_feed_dict)\n","  File \"/content/nmt/nmt/train.py\", line 176, in run_external_eval\n","    avg_ckpts=avg_ckpts)\n","  File \"/content/nmt/nmt/train.py\", line 730, in _external_eval\n","    infer_mode=hparams.infer_mode)\n","  File \"/content/nmt/nmt/utils/nmt_utils.py\", line 60, in decode_and_evaluate\n","    nmt_outputs, _ = model.decode(sess)\n","  File \"/content/nmt/nmt/model.py\", line 692, in decode\n","    output_tuple = self.infer(sess)\n","  File \"/content/nmt/nmt/model.py\", line 680, in infer\n","    return sess.run(output_tuple)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n","    options, feed_dict, fetch_list, target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","\n","saved\n","\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","# Job id 0\n","2019-06-01 17:52:13.306694: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-06-01 17:52:13.306896: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x240a680 executing computations on platform Host. Devices:\n","2019-06-01 17:52:13.306927: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-06-01 17:52:13.470896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-01 17:52:13.471419: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2409fa0 executing computations on platform CUDA. Devices:\n","2019-06-01 17:52:13.471451: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-06-01 17:52:13.471779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.73GiB freeMemory: 14.60GiB\n","2019-06-01 17:52:13.471801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:52:13.914590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:52:13.914653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:52:13.914664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:52:13.914908: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-06-01 17:52:13.914949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 9534781756877982213), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4447860105272542286), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 13296297171923826683), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 14800692839, 5808857627786536612)]\n","# Loading hparams from nmt_model/hparams\n","# Vocab file ../revocab.train.bpe.a exists\n","The first 3 vocab words [@@, .@@, the] are not [<unk>, <s>, </s>]\n","# Vocab file ../revocab.train.bpe.b exists\n","The first 3 vocab words [@@, .@@, i] are not [<unk>, <s>, </s>]\n","  saving hparams to nmt_model/hparams\n","  saving hparams to nmt_model/best_bleu/hparams\n","  attention=\n","  attention_architecture=standard\n","  avg_ckpts=False\n","  batch_size=16\n","  beam_width=0\n","  best_bleu=0.2515733643254677\n","  best_bleu_dir=nmt_model/best_bleu\n","  check_special_token=True\n","  colocate_gradients_with_ops=True\n","  coverage_penalty_weight=0.0\n","  decay_scheme=\n","  dev_prefix=../test.bpe\n","  dropout=0.2\n","  embed_prefix=None\n","  encoder_type=uni\n","  eos=</s>\n","  epoch_step=13\n","  forget_bias=1.0\n","  infer_batch_size=32\n","  infer_mode=greedy\n","  init_op=uniform\n","  init_weight=0.1\n","  language_model=False\n","  learning_rate=0.2\n","  length_penalty_weight=0.0\n","  log_device_placement=False\n","  max_gradient_norm=5.0\n","  max_train=0\n","  metrics=['bleu']\n","  num_buckets=5\n","  num_dec_emb_partitions=0\n","  num_decoder_layers=2\n","  num_decoder_residual_layers=0\n","  num_embeddings_partitions=0\n","  num_enc_emb_partitions=0\n","  num_encoder_layers=2\n","  num_encoder_residual_layers=0\n","  num_gpus=1\n","  num_inter_threads=0\n","  num_intra_threads=0\n","  num_keep_ckpts=5\n","  num_sampled_softmax=0\n","  num_train_steps=437690\n","  num_translations_per_input=1\n","  num_units=128\n","  optimizer=sgd\n","  out_dir=nmt_model\n","  output_attention=True\n","  override_loaded_hparams=False\n","  pass_hidden_state=True\n","  random_seed=None\n","  residual=False\n","  sampling_temperature=0.0\n","  share_vocab=False\n","  sos=<s>\n","  src=a\n","  src_embed_file=\n","  src_max_len=50\n","  src_max_len_infer=None\n","  src_vocab_file=nmt_model/revocab.train.bpe.a\n","  src_vocab_size=15230\n","  steps_per_external_eval=None\n","  steps_per_stats=769\n","  subword_option=\n","  test_prefix=../test.bpe\n","  tgt=b\n","  tgt_embed_file=\n","  tgt_max_len=50\n","  tgt_max_len_infer=None\n","  tgt_vocab_file=nmt_model/revocab.train.bpe.b\n","  tgt_vocab_size=14906\n","  time_major=True\n","  train_prefix=../train.bpe\n","  unit_type=lstm\n","  use_char_encode=False\n","  vocab_prefix=../revocab.train.bpe\n","  warmup_scheme=t2t\n","  warmup_steps=0\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:129: DatasetV1.shard (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `dataset.apply(tf.data.experimental.filter_for_shard(...))`.\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.group_by_window(...)`.\n","WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","# Creating train graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n","  learning_rate=0.2, warmup_steps=0, warmup_scheme=t2t\n","  decay_scheme=, start_decay_step=437690, decay_steps 0, decay_factor 1\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), /device:GPU:0\n","# Creating eval graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), /device:GPU:0\n","# Creating infer graph ...\n","# Build a basic encoder\n","  num_layers = 2, num_residual_layers=0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n","  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000\n","# Trainable variables\n","Format: <name>, <shape>, <(soft) device placement>\n","  embeddings/encoder/embedding_encoder:0, (15230, 128), /device:GPU:0\n","  embeddings/decoder/embedding_decoder:0, (14906, 128), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n","  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n","  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 14906), \n","# log_file=nmt_model/log_1559411537\n","2019-06-01 17:52:17.203630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:52:17.203698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:52:17.203713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:52:17.203725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:52:17.204131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-06-01 17:52:17.206166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:52:17.206230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:52:17.206249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:52:17.206263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:52:17.206652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-06-01 17:52:17.208181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-06-01 17:52:17.208238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-01 17:52:17.208257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-06-01 17:52:17.208271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-06-01 17:52:17.208624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","  loaded train model parameters from nmt_model/translate.ckpt-457690, time 0.20s\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.07s\n","  # 1582\n","2019-06-01 17:52:17.822400: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","    src: hey, there's our re@@ si@@ d@@ ent bu@@ l@@ l pan@@ da@@ , p@@ ing p@@ ing. with any lu@@ ck@@ , folks, these two will become ver@@ y, very clo@@ se, if you know what i mean@@ .\n","    ref: huh? help! mr. burns!\n","    nmt: huh?\n","  loaded eval model parameters from nmt_model/translate.ckpt-457690, time 0.08s\n","  eval dev: perplexity 784.00, time 6s, Sat Jun  1 17:52:25 2019.\n","  eval test: perplexity 784.00, time 7s, Sat Jun  1 17:52:32 2019.\n","2019-06-01 17:52:32.618617: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","2019-06-01 17:52:32.618693: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.a is already initialized.\n","2019-06-01 17:52:32.618806: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file nmt_model/revocab.train.bpe.b is already initialized.\n","  loaded infer model parameters from nmt_model/translate.ckpt-457690, time 0.04s\n","# External evaluation, global step 457690\n","  decoding to output nmt_model/output_dev\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5yeOgzDtHOuX","colab_type":"text"},"source":["Após o treinamento, podemos criar uma função para conversar com a rede neural, fazendo inferências novas a partir de um arquivo `input.txt`:"]},{"cell_type":"code","metadata":{"id":"DVS7LT9d_ABz","colab_type":"code","colab":{}},"source":["def chatbot_seq2seq():\n","  quit = False\n","  while(quit == False):\n","    text = input(\"Me: \")\n","    \n","    if(text == \"quit()\"):\n","      quit = True\n","      \n","    else:\n","      with open(\"/content/input.txt\", \"w\") as input_file:\n","        input_file.write(text)\n","  \n","      !/content/subword-nmt/apply_bpe.py -c /content/code.bpe --vocabulary /content/vocab.train.bpe.a --vocabulary-threshold 5 < /content/input.txt > /content/input.bpe\n","      !cd /content/nmt && python -m nmt.nmt \\\n","        --out_dir=nmt_model \\\n","        --inference_input_file=/content/input.bpe \\\n","        --inference_output_file=/content/output.txt > /dev/null 2>&1\n","  \n","      with open(\"/content/output.txt\", \"r\") as output:\n","        print('Homer: ', output.read().replace('@@ ', '').strip(\"@@\\n\"))\n","        print('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4s4k96p0kQP","colab_type":"code","outputId":"a34dd77a-0e5b-4c8b-b303-e73d06fc44c1","executionInfo":{"status":"ok","timestamp":1560014445860,"user_tz":180,"elapsed":51699,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Célula para rodar a função de chatbot\n","chatbot_seq2seq()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Me: hey old friend\n","chatbot:  marge, i do that stupid du\n","\n","\n","Me: quit()\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9jq4xC9gIFZg","colab_type":"text"},"source":["## 4. Modelo Doc2Vec\n","\n","O modelo Doc2Vec é semelhante ao Seq2Seq no sentido de percepção de \"sentido\" para frases, mas ele só vai até aí. Dentro de si, ele utiliza o modelo Word2Vec, que atribui significado a palavras em vetores numéricos, mas vai um passo além e usa os significados de múltiplas palavras para inferir o significado de uma frase - um \"**doc**umento\".\n","\n","![alt text](https://drive.google.com/uc?id=1jZ_Om2unMFtlodKWECXAb7w4OJY4TJLH)\n","\n","Tendo o vetor que representa a frase de entrada, procuramos dentre todas as falas de Os Simpsons que foram faladas para o Homer, qual é a mais parecida, ou seja, qual vetor é mais similar (ou próximo) ao vetor gerado pelo modelo, e retornamos a resposta que o Homer deu para esta frase. Isso configura um modelo de diálogo \"retrieval-based\", ou seja, baseado em busca de frases já prontas, diferentemente dos modelos generativos, que geram texto novo.\n","\n","A biblioteca que vamos usar para isso é a [gensim](https://radimrehurek.com/gensim/tutorial.html), também originalmente publicada pela Google, que serve para implementação de modelos Word2Vec e Doc2Vec.\n","\n","Nessa versão, como não vamos gerar conteúdo novo, vamos criar um vocabulário com palavras inteiras mesmo, onde palavras que aparecem apenas uma vez são ignoradas e tratadas como palavras desconhecidas."]},{"cell_type":"markdown","metadata":{"id":"kn6l-mdzyE8p","colab_type":"text"},"source":["Rode a próxima célula de código se e somente se quiser carregar o modelo pré-treinado do Drive:"]},{"cell_type":"code","metadata":{"id":"SMyboyB9yNCK","colab_type":"code","outputId":"cb76cd8c-57ec-4728-c427-3a7d69350ffe","executionInfo":{"status":"ok","timestamp":1560006991099,"user_tz":180,"elapsed":10240,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Carregando modelo treinado anteriormente\n","import gensim\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.utils import simple_preprocess\n","import multiprocessing\n","import os\n","\n","!rm -rf /content/doc2vec.model\n","!rm -rf /content/doc2vec.model.docvecs.vectors_docs.npy\n","!cp /content/gdrive/My\\ Drive/homer_chatbot/doc2vec.model /content/doc2vec.model\n","!cp /content/gdrive/My\\ Drive/homer_chatbot/doc2vec.model.docvecs.vectors_docs.npy /content/doc2vec.model.docvecs.vectors_docs.npy\n","\n","doc2vec_model = Doc2Vec.load(\"/content/doc2vec.model\")\n","\n","!echo -e \"\\nloaded\\n\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["\n","loaded\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L0R2nanIe9no","colab_type":"text"},"source":["E caso queira treinar..."]},{"cell_type":"code","metadata":{"id":"x2PzAHCgLKQD","colab_type":"code","outputId":"243ecb48-15f5-4d28-a14f-4b3468d1a26f","executionInfo":{"status":"ok","timestamp":1560006888739,"user_tz":180,"elapsed":135690,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["# Treinando o modelo\n","import gensim\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.utils import simple_preprocess\n","import multiprocessing\n","import os\n","\n","# Só tendo certeza de que será usado o compilador C (para treinar mais rápido)\n","assert gensim.models.doc2vec.FAST_VERSION > -1\n","\n","print('Fazendo uns paranauês matemáticos...')\n","\n","# Precisamos do número de palavras no conjunto de treino\n","with open(\"questions.txt\", \"r\") as f:\n","  n_words = len(f.read().split())\n","\n","cores = multiprocessing.cpu_count()\n","\n","# Criando o modelo com 200 dimensões de vetores, palavras que\n","# aparecem no mínimo 2 vezes e com o número certinho de cores\n","doc2vec_model = Doc2Vec(vector_size=200, min_count=2, workers=cores)\n","doc2vec_model.build_vocab(corpus_file=\"questions.txt\")\n","doc2vec_model.train(corpus_file=\"questions.txt\",\n","                    total_words=n_words,\n","                    epochs=100)\n","\n","if not os.path.exists(\"models\"):\n","    os.makedirs(\"models\")\n","\n","doc2vec_model.save('models/doc2vec.model')\n","\n","# Salvando o modelo\n","!rm -rf /content/gdrive/My\\ Drive/homer_chatbot/doc2vec.model\n","!cp /content/models/doc2vec.model /content/gdrive/My\\ Drive/homer_chatbot/doc2vec.model\n","!cp /content/models/doc2vec.model.docvecs.vectors_docs.npy /content/gdrive/My\\ Drive/homer_chatbot/doc2vec.model.docvecs.vectors_docs.npy\n","!echo -e \"\\nsaved\\n\"\n","\n","print('Feito!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fazendo uns paranauês matemáticos...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["\n","saved\n","\n","Feito!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"THrgtpbqOJb5","colab_type":"text"},"source":["Para testar e ver o funcionamento do Doc2Vec, vamos fazer um \"teste de sanidade\" - retorno das 2 palavras mais parecidas com outra qualquer"]},{"cell_type":"code","metadata":{"id":"6LRdrh-YOKCa","colab_type":"code","outputId":"0d313c4b-6537-41ed-97d3-70c28f409b57","executionInfo":{"status":"ok","timestamp":1560007005319,"user_tz":180,"elapsed":1202,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 'Sanity Test'\n","import warnings\n","\n","# Um filtro de warnings chatos, pra não atrapalharem a apresentação...\n","with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    \n","    # vetor com palavras mais parecidas\n","    print(doc2vec_model.wv.most_similar(['nice'])[0:2])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('good', 0.46582120656967163), ('well,', 0.4623730182647705)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aLNafmo_Ol5C","colab_type":"text"},"source":["... E a função de chatbot é feita usando o método `most_similar` no vetor inferido a partir de uma frase nova:"]},{"cell_type":"code","metadata":{"id":"GgjuVEGOOtrw","colab_type":"code","colab":{}},"source":["import warnings\n","\n","with open(\"answers.txt\") as f:\n","    answers = f.read().split(\"\\n\")\n","\n","# A função de ChatBot em si\n","def chatbot_doc2vec():\n","    quit=False\n","    while quit == False:\n","        text = input('Me: ').lower()\n","        # Um comando de quit opcional\n","        if text == 'quit()':\n","            quit=True\n","        else:\n","            tokens = text.split()\n","            # Infere vetor para o texto que o modelo pode não ter visto ainda\n","            new_vector = doc2vec_model.infer_vector(tokens)\n","            \n","            with warnings.catch_warnings():\n","                warnings.simplefilter(\"ignore\")\n","                \n","                # 15248 é o último índice das linhas com respostas do Homer,\n","                # é até onde o modelo pode pegar frases para responder.\n","                index = doc2vec_model.docvecs.most_similar([new_vector], topn=1, clip_end=15248)\n","\n","            # index é uma lista de tuplas (index no arquivo de treino, similaridade)\n","            print(\"Homer: \", answers[index[0][0]])\n","            print('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcIzuOx66Qal","colab_type":"code","outputId":"48610941-5eb3-452a-f1b0-d900ebf6bc4e","executionInfo":{"status":"error","timestamp":1560014062913,"user_tz":180,"elapsed":1622414,"user":{"displayName":"Marcos Landi","photoUrl":"","userId":"04696937553265225531"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["chatbot_doc2vec()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Me: what's your favourite hobby?\n","chatbot:  oh... it's a special time in a boy's life when... gotta go! so come to the legless frog... if you want to get sick and die, and leave a big, garlicky corpse. p.s. parking was ample.\n","\n","\n","Me: when were you born?\n","chatbot:  no! you're wrong! check again!\n","\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-69fac43a64e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot_doc2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-9073dff0f155>\u001b[0m in \u001b[0;36mchatbot_doc2vec\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mquit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mquit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Me: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Um comando de quit opcional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit()'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"yJN71AjRoJtO","colab_type":"text"},"source":["## 5. Experimentação\n","\n","Com o chatbot em mãos, testamos as capacidades do nosso chatbot com outras pessoas, para validar o quão bom ele é. Fizemos o seguinte: apresentamos as duas versões do chatbot, explicando a diferença entre elas, mas sem dizer qual personagem é, e pedimos para a pessoa tentar descobrir qual é. Afinal, se o único propósito deste robô é ser o Homer Simpson, vamos testar o quão Homer Simpson ele é.\n","\n","---\n","\n","![alt text](https://drive.google.com/uc?id=12caEi1Yy5dMmT8qnJ9vL4DCgzUeS1VDN)\n","\n","---\n","\n","Testando com uma colega com quem eu nunca falei, ele me fala uma coisa dessas na primeira resposta - mas tudo bem, ela entendeu que ele não faz muito sentido. Conversando um pouco com a primeira versão, ela viu que seria melhor tentar com a outra, que podia fazer mais sentido.\n","\n","Foi nesse momento que um outro colega que estava asstindo teve a ideia de perguntar qual o nome dele, e ele respondeu de acordo:\n","\n","---\n","\n","![alt text](https://drive.google.com/uc?id=1YJTqAXks42HHn5XoAqoXZomGoY5bhWuZ)\n","\n","---\n","\n","(note a desconsideração da máquina para com sua nova amiga no final)\n","\n","---\n","\n","![alt text](https://drive.google.com/uc?id=1yuqustjsMenJz9Q2amHHgt03-yp4I3VL)\n","\n","---\n","\n","Literalmente na primeira resposta, o Homer se entrega, gritando 'Bart!' - e isso que o colega estava super interessado em conversar com o chatbot...\n","\n","---\n","\n","![alt_text](https://drive.google.com/uc?id=130I4VgSE-4EMBDXMzKUMgW8-bqwnT7I8)\n","\n","---\n","\n","Ele parece gostar de chamar a pessoa com quem está interagindo de \"Marge\", o que faz sentido, pela alta porcentagem das falas do Homer que foram com a Marge.\n","\n","---\n","\n","![alt_text](https://drive.google.com/uc?id=1tbCUwDBshzN0tXrfc4LEWIcZf-N4p2VS)\n","\n","---\n","\n","Ele também parece não entender abreviações direito, respondendo melhor às frases mais gramaticamente corretas.\n","\n","Mais alguns momentos relevantes:\n","\n","---\n","\n","![alt text](https://drive.google.com/uc?id=1dEY5Y49uEcjCaHDlWuveoG9uhfMkZH-a)\n","\n","---\n","\n","![alt text](https://drive.google.com/uc?id=1n5Piww_s4WS60NM3GpPcYezSCoE9pvN_)\n","\n","---\n","\n","Todos os diálogos completos da parte de experimentação estão no repositório do github."]},{"cell_type":"markdown","metadata":{"id":"-mTaW0-QTME9","colab_type":"text"},"source":["## 6. Conclusão\n","\n","Com os resultados no mínimo estranhos, concluímos que o conjunto de dados era pequeno demais para uma aprendizagem de contexto das palavras e suas relações boa o bastante, para ambos modelos. Mas também que existem modelos de redes neurais que são mais adequados para diferentes conjuntos de dados e objetivos de processamento de linguagem natural.\n","\n","Na experimentação, vimos que os chatbots, apesar de tudo, têm uma semelhança com o Homer Simpson, com uma personalidade parecida e de vez em quando mencionando outros personagens da série. Isso é óbvio no caso do modelo Doc2Vec, mas ficamos surpresos com estes resultados do modelo Seq2Seq.\n","\n","Para fazer uma ligação com o que aprendemos na cadeira, vamos entender como funcionam modelos de aprendizado de máquina, comparando com expressões regulares e autômatos:\n","\n","Autômatos são criados a partir de algoritmos, que, assim como expressões regulares, podem ser criados de maneira racional para prever contextos diferentes de um diálogo. Porém isto está limitado à imaginação e observação do programador, de identificar e prever programáticamente tais contextos.\n","\n","Porém algoritmos de aprendizado de máquina são diferentes, pois **aprendem** quais os melhores parâmetros para um determinado modelo, como as redes neurais. Neles, o trabalho do programador ~~(além de passar noites tentando entender como implementar)~~ é apenas escolher os parâmetros certos, que potencialmente serão relevantes para o resultado final, e deixar o modelo treinar pela quantidade de tempo certa."]},{"cell_type":"markdown","metadata":{"id":"eDF8OI8MZCyL","colab_type":"text"},"source":["## 7. Links Úteis\n","\n","[Nosso repositório](https://github.com/mswlandi/homer-chatbot)\n","\n","### Seq2Seq\n","\n","[Nossa referência para o modelo Seq2Seq](https://blog.kovalevskyi.com/how-to-create-a-chatbot-with-tf-seq2seq-for-free-e876ea99063c)\n","\n","[Página da Google do seq2seq](https://google.github.io/seq2seq/)\n","\n","### Doc2Vec\n","\n","[Nossa referência para o modelo Doc2Vec](https://towardsdatascience.com/how-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d)\n","\n","[A gentle Introduction to Doc2Vec](https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)\n","\n","[(Outro caderno Jupyter) - Tutorial de Doc2Vec](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb)"]}]}